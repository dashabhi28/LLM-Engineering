{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfa9ae6-69fe-444a-b994-8c4c5970a7ec",
   "metadata": {},
   "source": [
    "***Airline ticket assistant***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43857ef1-9caf-440f-8932-1400de634f79",
   "metadata": {},
   "source": [
    "***Import Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b50bbe2-c0b1-49c3-9a5c-1ba7efa2bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f460a7-142a-48ec-8c11-fb1c958b40da",
   "metadata": {},
   "source": [
    "***Load environment***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "747e8786-9da8-4342-b6c9-f5f69c2e22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv(override=True)\n",
    "\n",
    "# openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# if openai_api_key:\n",
    "#     print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "# else:\n",
    "#     print(\"OpenAI API Key not set\")\n",
    "    \n",
    "# MODEL = \"gpt-4o-mini\"\n",
    "# openai = OpenAI()\n",
    "\n",
    "# As an alternative, if you'd like to use Ollama instead of OpenAI\n",
    "# Check that Ollama is running for you locally (see week1/day2 exercise) then uncomment these next 2 lines\n",
    "MODEL = \"llama3.2\"\n",
    "openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5d12d5-fda6-47e0-9de6-4cef8a5d33a8",
   "metadata": {},
   "source": [
    "***Prompts setup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a521d84-d07c-49ab-a0df-d6451499ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called Flighty. \"\n",
    "system_message += \"Give short, sarcastic answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, please say I dont know.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c77ee66-475a-474a-b4ec-b7fca4f181f0",
   "metadata": {},
   "source": [
    "***Gradio UI, along with chat function in the format needed by Gradio***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61a2a15d-b559-4844-b377-6bd5cb4949f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://b578ca082f38835f96.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b578ca082f38835f96.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3dcbe2-1455-4364-bbc2-1b6b9a0d6ab4",
   "metadata": {},
   "source": [
    "***Function & Tools***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0696acb1-0b05-4dc2-80d5-771be04f1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80ca4e09-6287-4d3f-997d-fa6afbcf6c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for Berlin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$499'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"Berlin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc679b5-0701-4a38-bfea-6539a3dcdcd2",
   "metadata": {},
   "source": [
    "This code defines a Python dictionary named price_function. This dictionary is structured in a way that is commonly used to describe a function for a language model to call, often referred to as ***\"tool calling\" or \"function calling\"***.\n",
    "\n",
    "Here's a breakdown of the key-value pairs in the dictionary:\n",
    "\n",
    "\"name\": \"get_ticket_price\": This specifies the name of the function that the language model should call.\n",
    "\"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\": This provides a clear description of what the function does and when the language model should consider calling it. This helps the model understand the purpose of the tool.\n",
    "\"parameters\": { ... }: This nested dictionary describes the parameters that the get_ticket_price function expects.\n",
    "\"type\": \"object\": Indicates that the parameters are structured as an object (in this case, a JSON object).\n",
    "\"properties\": { ... }: This nested dictionary lists the individual parameters of the function.\n",
    "\"destination_city\": { ... }: This describes a single parameter named destination_city.\n",
    "\"type\": \"string\": Specifies that the destination_city parameter should be a string.\n",
    "\"description\": \"The city that the customer wants to travel to\": Provides a description of what the destination_city parameter represents.\n",
    "\"required\": [\"destination_city\"]: This list specifies which of the defined properties are required. In this case, destination_city is a required parameter.\n",
    "\"additionalProperties\": False: This indicates that no additional parameters beyond those explicitly listed in properties are allowed.\n",
    "In summary, the price_function dictionary is a structured definition of a function that a language model can use to get the price of a ticket. It tells the model the function's name, what it does, what information it needs (destination_city), and that this information is required. This allows the language model to understand how and when to use this tool to fulfill a user's request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4afceded-7178-4c05-8fa6-9f2085e6a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdca8679-935f-4e7f-97e6-e71a4d4f228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d73fa-47eb-4726-9c95-93ee8ebec8da",
   "metadata": {},
   "source": [
    "***Chat function for interaction with LLM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce9b0744-9c78-408d-b9df-9f6fd9ed78cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools) #tools added to chat function\n",
    "\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response, city = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e399c-b563-4d42-8632-520eadde8a12",
   "metadata": {},
   "source": [
    "***Tool call function***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead71d8-d6d8-4ed8-814a-212236172f72",
   "metadata": {},
   "source": [
    "This Python function handle_tool_call is designed to process a specific type of message received from a language model that indicates the model wants to call a tool (or function).\n",
    "\n",
    "Here's a breakdown:\n",
    "\n",
    "def handle_tool_call(message):: Defines the function handle_tool_call that takes one argument, message, which is expected to be a message object from the language model's response.\n",
    "tool_call = message.tool_calls[0]: Accesses the first tool call in the tool_calls list within the message object. A message from a language model might contain a list of tool calls if the model decides to use one or more tools in response to the user's input. This line assumes there is at least one tool call and takes the first one.\n",
    "arguments = json.loads(tool_call.function.arguments): Extracts the arguments that the language model wants to pass to the function.\n",
    "tool_call.function.arguments: This accesses the arguments provided by the model for the function call. These arguments are typically in a JSON string format.\n",
    "json.loads(...): Parses the JSON string into a Python dictionary, making it easy to access the individual arguments by their keys.\n",
    "city = arguments.get('destination_city'): Retrieves the value associated with the key 'destination_city' from the arguments dictionary. The .get() method is used here, which is safer than direct dictionary access (arguments['destination_city']) because it will return None if the key doesn't exist, preventing a KeyError.\n",
    "price = get_ticket_price(city): Calls another function, get_ticket_price, passing the extracted city as an argument. This is where the actual work of getting the ticket price happens. The result is stored in the price variable.\n",
    "response = { ... }: Constructs a dictionary representing the response that needs to be sent back to the language model after the tool call is executed. This response informs the model about the result of the tool call.\n",
    "\"role\": \"tool\": Indicates that this message is from a \"tool\".\n",
    "\"content\": json.dumps({\"destination_city\": city,\"price\": price}): Provides the result of the tool call. It's a JSON string containing the destination_city and the fetched price. This information is what the language model will use to formulate its final response to the user.\n",
    "\"tool_call_id\": tool_call.id: Includes the ID of the tool call that this response corresponds to. This helps the language model match the tool call response to the original tool call request.\n",
    "return response, city: The function returns two values: the response dictionary (to be sent back to the language model) and the extracted city. Returning the city might be useful for subsequent steps in the conversation flow.\n",
    "In summary, the handle_tool_call function acts as an intermediary when a language model wants to use a predefined tool (like getting a ticket price). It parses the model's request, executes the corresponding function (get_ticket_price), and formats the result in a way that the language model can understand and use to generate a final user-facing response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0992986-ea09-4912-a076-8e5603ee631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    city = arguments.get('destination_city')\n",
    "    price = get_ticket_price(city)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}),\n",
    "        \"tool_call_id\": tool_call.id\n",
    "    }\n",
    "    return response, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4be8a71-b19e-4c2f-80df-f59ff2661f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for \n",
      "Tool get_ticket_price called for London\n",
      "Tool get_ticket_price called for London\n",
      "Tool get_ticket_price called for London\n",
      "Tool get_ticket_price called for London\n",
      "Tool get_ticket_price called for London\n",
      "Tool get_ticket_price called for London\n",
      "Tool get_ticket_price called for Berlin\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc60fe9-8215-4591-8531-9d8788c8332f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
