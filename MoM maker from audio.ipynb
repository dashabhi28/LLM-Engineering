{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KSMxOCprsl1QRpt_Rq0UqCAyMtPqDQYx","timestamp":1750912112836}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["***Create meeting minutes from an Audio file***"],"metadata":{"id":"It89APiAtTUF"}},{"cell_type":"code","source":["!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n","!pip install -q requests bitsandbytes==0.46.0 transformers==4.48.3 accelerate==1.3.0 openai"],"metadata":{"id":"f2vvgnFpHpID"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FW8nl3XRFrz0"},"outputs":[],"source":["# imports\n","\n","import os\n","import requests\n","from IPython.display import Markdown, display, update_display\n","from openai import OpenAI\n","from google.colab import drive\n","from huggingface_hub import login\n","from google.colab import userdata\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig, AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n","import torch"]},{"cell_type":"code","source":["# Constants\n","\n","AUDIO_MODEL = \"whisper-1\"\n","LLAMA = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""],"metadata":{"id":"q3D1_T0uG_Qh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Audio source on G drive\n","\n","drive.mount(\"/content/drive\")\n","audio_filename = \"/content/drive/MyDrive/Colab Notebooks/denver_extract.mp3\""],"metadata":{"id":"Es9GkQ0FGCMt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sign in to HuggingFace Hub\n","\n","hf_token = userdata.get('HF_Token')\n","login(hf_token, add_to_git_credential=True)"],"metadata":{"id":"xYW8kQYtF-3L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sign in to OpenAI using Secrets in Colab\n","\n","openai_api_key = userdata.get('OPENAI_API_KEY')\n","openai = OpenAI(api_key=openai_api_key)"],"metadata":{"id":"qP6OB2OeGC2C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["audio_file = open(audio_filename, \"rb\")\n","transcription = openai.audio.transcriptions.create(model=AUDIO_MODEL, file=audio_file, response_format=\"text\")\n","print(transcription)"],"metadata":{"id":"GMShdVGlGGr4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["system_message = \"You are an assistant that produces minutes of meetings from transcripts, with summary, key discussion points, takeaways and action items with owners, in markdown.\"\n","user_prompt = f\"Below is an extract transcript of a Denver council meeting. Please write minutes in markdown, including a summary with attendees, location and date; discussion points; takeaways; and action items with owners.\\n{transcription}\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": system_message},\n","    {\"role\": \"user\", \"content\": user_prompt}\n","  ]\n"],"metadata":{"id":"piEMmcSfMH-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["quant_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    bnb_4bit_quant_type=\"nf4\"\n",")"],"metadata":{"id":"UcRKUgcxMew6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(LLAMA)\n","tokenizer.pad_token = tokenizer.eos_token\n","inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n","streamer = TextStreamer(tokenizer)\n","model = AutoModelForCausalLM.from_pretrained(LLAMA, device_map=\"auto\", quantization_config=quant_config)\n","outputs = model.generate(inputs, max_new_tokens=2000, streamer=streamer)"],"metadata":{"id":"6CujZRAgMimy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = tokenizer.decode(outputs[0])"],"metadata":{"id":"102tdU_3Peam"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(Markdown(response))"],"metadata":{"id":"KlomN6CwMdoN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["***Free source transcritption***"],"metadata":{"id":"AU3uAEyU3a-o"}},{"cell_type":"code","source":["AUDIO_MODEL = \"openai/whisper-medium\"\n","speech_model = AutoModelForSpeechSeq2Seq.from_pretrained(AUDIO_MODEL, torch_dtype=torch.float16, low_cpu_mem_usage=True, use_safetensors=True)\n","speech_model.to('cuda')\n","processor = AutoProcessor.from_pretrained(AUDIO_MODEL)\n","\n","pipe = pipeline(\n","    \"automatic-speech-recognition\",\n","    model=speech_model,\n","    tokenizer=processor.tokenizer,\n","    feature_extractor=processor.feature_extractor,\n","    torch_dtype=torch.float16,\n","    device='cuda',\n",")"],"metadata":{"id":"HdQnWEzW3lzP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use the Whisper OpenAI model to convert the Audio to Text\n","result = pipe(audio_filename, return_timestamps=True)"],"metadata":{"id":"nrQjKtD53omJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transcription = result[\"text\"]\n","display(Markdown(transcription))"],"metadata":{"id":"G_XSljOY3tDf"},"execution_count":null,"outputs":[]}]}